{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMh+nQWatZni0L247wfI2W0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BOD-27/GP/blob/main/Final_Facerecognentin_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CmyRslwrUd6Q"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "def install_libraries():\n",
        "    !pip install mtcnn\n",
        "    !pip install keras-facenet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "def import_libraries():\n",
        "    global os, cv, np, plt, MTCNN, FaceNet, cosine, re, Counter\n",
        "    import os\n",
        "    import cv2 as cv\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    from mtcnn.mtcnn import MTCNN\n",
        "    from keras_facenet import FaceNet\n",
        "    from scipy.spatial.distance import cosine\n",
        "    import re\n",
        "    from collections import Counter"
      ],
      "metadata": {
        "id": "hotlIZuGUm80"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppress TensorFlow warnings\n",
        "def suppress_tf_warnings():\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "metadata": {
        "id": "UJMsoJkiUva2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "def mount_drive():\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6P9QQhf8Uz6C"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repository\n",
        "def clone_repo():\n",
        "    !git clone https://github.com/BOD-27/GP"
      ],
      "metadata": {
        "id": "25okFjrtU4Ey"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip datasets\n",
        "def unzip_datasets():\n",
        "    !unzip /content/GP/FinalTest_dataset.zip\n",
        "    !unzip /content/GP/Final_dataset.zip"
      ],
      "metadata": {
        "id": "4UpljTFiVBNu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory to save embeddings\n",
        "def create_embedding_save_directory():\n",
        "    embedding_save_directory = '/content/drive/My Drive/Embedding'\n",
        "    if not os.path.exists(embedding_save_directory):\n",
        "        os.makedirs(embedding_save_directory)\n",
        "    return embedding_save_directory"
      ],
      "metadata": {
        "id": "ihVaylXbVHW6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the FaceLoading class for loading and processing images\n",
        "class FaceLoading:\n",
        "    def __init__(self, directory):\n",
        "        self.directory = directory\n",
        "        self.target_size = (160, 160)\n",
        "        self.detector = MTCNN()\n",
        "\n",
        "    def ExtractFace(self, filename):\n",
        "        img = cv.imread(filename)\n",
        "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "        x, y, w, h = self.detector.detect_faces(img)[0]['box']\n",
        "        x, y = abs(x), abs(y)\n",
        "        face = img[y:y + h, x:x + w]\n",
        "        face_arr = cv.resize(face, self.target_size)\n",
        "        return face_arr\n",
        "\n",
        "    def LoadFace(self, file_path):\n",
        "        faces = []\n",
        "        try:\n",
        "            single_face = self.ExtractFace(file_path)\n",
        "            faces.append(single_face)\n",
        "        except Exception as e:\n",
        "            pass\n",
        "        return faces\n",
        "\n",
        "    def LoadClasses(self):\n",
        "        x = []\n",
        "        y = []\n",
        "        for file_name in os.listdir(self.directory):\n",
        "            if file_name.endswith('.jpg') or file_name.endswith('.png') or file_name.endswith('.jpeg'):\n",
        "                file_path = os.path.join(self.directory, file_name)\n",
        "                faces = self.LoadFace(file_path)\n",
        "                labels = [file_name] * len(faces)\n",
        "                print(f\"Loaded successfully: {len(labels)}\")\n",
        "                x.extend(faces)\n",
        "                y.extend(labels)\n",
        "        return np.asarray(x), np.asarray(y)\n",
        "\n",
        "    def encode_and_save_embeddings(self, embedding_save_directory):\n",
        "        X, y = self.LoadClasses()\n",
        "        embedder = FaceNet()\n",
        "        embedded_x = [self.GetEmbedding(embedder, img) for img in X]\n",
        "\n",
        "        # Save embeddings inside the created folder\n",
        "        for i, (embedding, label) in enumerate(zip(embedded_x, y)):\n",
        "            np.save(os.path.join(embedding_save_directory, f'{label}_embeddings.npy'), embedding)\n",
        "        return np.array(embedded_x), np.array(y)\n",
        "\n",
        "    def GetEmbedding(self, embedder, face_img):\n",
        "        face_img = face_img.astype('float32')\n",
        "        face_img = np.expand_dims(face_img, axis=0)\n",
        "        yhat = embedder.embeddings(face_img)\n",
        "        return yhat[0]\n",
        "\n",
        "    def load_or_encode_and_save_embeddings(self, embedding_save_directory):\n",
        "        embedding_files = [f for f in os.listdir(embedding_save_directory) if f.endswith('.npy')]\n",
        "\n",
        "        if not embedding_files:\n",
        "            print(\"Embeddings not found. Encoding and saving embeddings...\")\n",
        "            return self.encode_and_save_embeddings(embedding_save_directory)\n",
        "        else:\n",
        "            print(\"Embeddings found. Loading embeddings...\")\n",
        "            embedded_x, dataset_labels = [], []\n",
        "            for file in embedding_files:\n",
        "                data = np.load(os.path.join(embedding_save_directory, file))\n",
        "                embedded_x.append(data)\n",
        "                dataset_labels.append(file.replace('_embeddings.npy', ''))\n",
        "            embedded_x = np.asarray(embedded_x)\n",
        "            dataset_labels = np.asarray(dataset_labels)\n",
        "            return embedded_x, dataset_labels"
      ],
      "metadata": {
        "id": "PcEj2ksxVPqe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define functions for preprocessing, finding closest matches, and checking for match\n",
        "def preprocess_label(label):\n",
        "    label = re.sub(r'\\d+', '', label)\n",
        "    label = re.sub(r'\\.\\w{3,4}|\\.', '', label)\n",
        "    label = re.sub(r'\\[.*?\\]|\\(.*?\\)|\\{.*?\\}', '', label)\n",
        "    label = re.sub(r'_[\\w\\d]+.*$', '', label)\n",
        "    label = label.strip()\n",
        "    return label"
      ],
      "metadata": {
        "id": "HmA4pxaYVVbq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_closest_matches(embedded_input, embedded_dataset, dataset_labels, top_n=7):\n",
        "    distances = []\n",
        "    outlabels = []\n",
        "    for input_embedding in embedded_input:\n",
        "        distances_for_input = [cosine(input_embedding, dataset_embedding) for dataset_embedding in embedded_dataset]\n",
        "        min_distance_index = np.argmin(distances_for_input)\n",
        "        distances.append(distances_for_input[min_distance_index])\n",
        "        outlabels.append(dataset_labels[min_distance_index])\n",
        "\n",
        "    sorted_indices = np.argsort(distances)\n",
        "    sorted_distances = np.array(distances)[sorted_indices]\n",
        "    sorted_labels = np.array(outlabels)[sorted_indices]\n",
        "\n",
        "    top_matches = [(sorted_labels[i], sorted_distances[i]) for i in range(top_n)]\n",
        "    return top_matches"
      ],
      "metadata": {
        "id": "fXium-9iWjwJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_for_match(top_matches):\n",
        "    labels = [preprocess_label(label) for label, _ in top_matches]\n",
        "    distances = [distance for _, distance in top_matches]\n",
        "    frequent_labels = Counter(labels).most_common()\n",
        "\n",
        "    for label, count in frequent_labels:\n",
        "        if count >= 4:\n",
        "            label_distances = [distance for orig_label, distance in top_matches if preprocess_label(orig_label) == label]\n",
        "            avg_similarity = sum(label_distances) / count\n",
        "            if avg_similarity < 0.5:\n",
        "                return True, avg_similarity, label\n",
        "\n",
        "        elif count == 3:\n",
        "            label_distances = [distance for orig_label, distance in top_matches if preprocess_label(orig_label) == label]\n",
        "            avg_similarity = sum(label_distances) / count\n",
        "            if avg_similarity < 0.5:\n",
        "                return True, avg_similarity, label\n",
        "\n",
        "    return False, None, None"
      ],
      "metadata": {
        "id": "36bFSBpzVio8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the main function\n",
        "def main():\n",
        "    install_libraries()\n",
        "    import_libraries()\n",
        "    suppress_tf_warnings()\n",
        "    #mount_drive()\n",
        "    #clone_repo()\n",
        "    #unzip_datasets()\n",
        "\n",
        "    embedding_save_directory = create_embedding_save_directory()\n",
        "\n",
        "    # Initialize FaceLoading object\n",
        "    faceLoading = FaceLoading('/content/Final_dataset')\n",
        "\n",
        "    # Load or encode and save embeddings\n",
        "    embedded_x, dataset_labels = faceLoading.load_or_encode_and_save_embeddings(embedding_save_directory)\n",
        "\n",
        "    # Load and process new images for comparison\n",
        "    faceLoading2 = FaceLoading('/content/FinalTest_dataset/Marawan')\n",
        "    X1, y1 = faceLoading2.LoadClasses()\n",
        "\n",
        "    # Compute embeddings for new input images\n",
        "    embedder = FaceNet()\n",
        "    embedded_x1 = [faceLoading2.GetEmbedding(embedder, img) for img in X1]\n",
        "\n",
        "    # Find closest matches\n",
        "    top_matches = find_closest_matches(embedded_x1, embedded_x, dataset_labels, top_n=7)\n",
        "\n",
        "    # Print top 7 similar images and their similarity scores\n",
        "    for i, (label, distance) in enumerate(top_matches, 1):\n",
        "        print(f\"Similar Image {i}: Label - {label}, Similarity Score - {distance}\")\n",
        "\n",
        "    # Check for match\n",
        "    match_found, avg_similarity, matched_label = check_for_match(top_matches)\n",
        "\n",
        "    if match_found:\n",
        "        print(\"Match found with label:\", matched_label)\n",
        "        print(\"Average cosine similarity:\", avg_similarity)\n",
        "    else:\n",
        "        print(\"No match found. Adding embeddings...\")\n",
        "        # Save embeddings of test images as new embeddings\n",
        "        for i, img in enumerate(X1):\n",
        "            embedding = faceLoading2.GetEmbedding(embedder, img)\n",
        "            label = y1[i]\n",
        "            np.save(os.path.join(embedding_save_directory, f'{label}embeddings.npy'), embedding)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJhZlx2cV1KG",
        "outputId": "d7622bfd-43f5-4aab-a181-c7c51a13edb4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (2.15.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.25.2)\n",
            "Requirement already satisfied: keras-facenet in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.10/dist-packages (from keras-facenet) (0.1.1)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn->keras-facenet) (2.15.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn->keras-facenet) (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->mtcnn->keras-facenet) (1.25.2)\n",
            "Embeddings found. Loading embeddings...\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2/2 [==============================] - 0s 167ms/step\n",
            "1/1 [==============================] - 0s 212ms/step\n",
            "Loaded successfully: 1\n",
            "1/1 [==============================] - 0s 346ms/step\n",
            "1/1 [==============================] - 0s 263ms/step\n",
            "1/1 [==============================] - 0s 235ms/step\n",
            "1/1 [==============================] - 0s 202ms/step\n",
            "1/1 [==============================] - 0s 215ms/step\n",
            "1/1 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 0s 210ms/step\n",
            "1/1 [==============================] - 0s 229ms/step\n",
            "1/1 [==============================] - 0s 211ms/step\n",
            "1/1 [==============================] - 0s 180ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Loaded successfully: 1\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 115ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Loaded successfully: 1\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Loaded successfully: 1\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Loaded successfully: 1\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Loaded successfully: 1\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Loaded successfully: 1\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Similar Image 1: Label - Marawan3.png, Similarity Score - 0.19191652536392212\n",
            "Similar Image 2: Label - Marawan5.png, Similarity Score - 0.21465712785720825\n",
            "Similar Image 3: Label - Marawan5.png, Similarity Score - 0.22685092687606812\n",
            "Similar Image 4: Label - Marawan3.png, Similarity Score - 0.27489036321640015\n",
            "Similar Image 5: Label - Marawan3.png, Similarity Score - 0.27626287937164307\n",
            "Similar Image 6: Label - Marawan3.png, Similarity Score - 0.42181825637817383\n",
            "Similar Image 7: Label - Mohamed (1).png, Similarity Score - 0.43554025888442993\n",
            "Match found with label: Marawan\n",
            "Average cosine similarity: 0.2677326798439026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "54tvHaItV9S9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}