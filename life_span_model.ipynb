{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BOD-27/GP/blob/main/life_span_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VtCmf3IcH5uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jny9CGNw1Rjn"
      },
      "source": [
        "# Lifespan Age Transformation Synthesis Demo\n",
        "\n",
        "This Colab notebook demonstrates the capabilities of the GAN architecture proposed in our paper.\n",
        "\n",
        "This colab lets you try our method on your own image!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhbnEdCV2kc-"
      },
      "source": [
        "First, let's download the github repository and install all dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2uubo7PsvxQ"
      },
      "source": [
        "!git clone https://github.com/royorel/Lifespan_Age_Transformation_Synthesis\n",
        "%cd Lifespan_Age_Transformation_Synthesis/\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKKNh_xl3AI2"
      },
      "source": [
        "Now let's download the pretrained models for males and females."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ezAOkaHw4Q_"
      },
      "source": [
        "!python download_models.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKl8INdX3IHv"
      },
      "source": [
        "Here, we import libraries and set options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQKoh2xrw697"
      },
      "source": [
        "import os\n",
        "from collections import OrderedDict\n",
        "from options.test_options import TestOptions\n",
        "from data.data_loader import CreateDataLoader\n",
        "from models.models import create_model\n",
        "import util.util as util\n",
        "from util.visualizer import Visualizer\n",
        "\n",
        "opt = TestOptions().parse(save=False)\n",
        "opt.display_id = 0 # do not launch visdom\n",
        "opt.nThreads = 1   # test code only supports nThreads = 1\n",
        "opt.batchSize = 1  # test code only supports batchSize = 1\n",
        "opt.serial_batches = True  # no shuffle\n",
        "opt.no_flip = True  # no flip\n",
        "opt.in_the_wild = True # This triggers preprocessing of in the wild images in the dataloader\n",
        "opt.traverse = False # This tells the model to traverse the latent space between anchor classes\n",
        "opt.interp_step = 0.05 # this controls the number of images to interpolate between anchor classes\n",
        "opt.deploy = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLOiDzgKtYyi"
      },
      "source": [
        "Don't worry about this message above,\n",
        "```\n",
        "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-c9d47a98-bdba-4a5f-9f0a-e1437c7228b6.json\n",
        "```\n",
        "everything is perfectly fine..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AFlzSi41Kzg"
      },
      "source": [
        "Next on, we call the data loader and the visualizer class that generates the video from the network outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxBYeTB18zkZ"
      },
      "source": [
        "data_loader = CreateDataLoader(opt)\n",
        "dataset = data_loader.load_data()\n",
        "visualizer = Visualizer(opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AbUVdK74G5p"
      },
      "source": [
        "Here, we define our model.\n",
        "\n",
        "NOTE: if you plan to try the method for a female, change opt.name to 'females_model'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_0RChfq0YPr"
      },
      "source": [
        "def load_model(model_name):\n",
        "    opt.name = model_name\n",
        "    model = create_model(opt)\n",
        "    model.eval()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def switch_model_gender(gender):\n",
        "    if gender.lower() == 'male':\n",
        "        return load_model('males_model')\n",
        "    elif gender.lower() == 'female':\n",
        "        return load_model('females_model')\n",
        "    else:\n",
        "        raise ValueError(\"Invalid gender provided. Please provide either 'male' or 'female'.\")\n"
      ],
      "metadata": {
        "id": "ROPcNkek7s1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "selected_gender = 'female'  # This could be dynamically set from the backend\n",
        "model = switch_model_gender(selected_gender)"
      ],
      "metadata": {
        "id": "IcmBKrccCjxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APhLIBEg4gnk"
      },
      "source": [
        "OK, it's time to upload your image.\n",
        "\n",
        "For best results, use images according to the following guidelines:\n",
        "\n",
        "1. The image should contain a single face.\n",
        "2. Image was taken from a digital camera (phone cameras are fine). Old images from film cameras would produce low quality results.\n",
        "3. Pure RGB images only. No black & white, grayscale, sepia, or filtered images (e.g. Instagram filters).\n",
        "4. Person's head should directly face the camera. Looking sideways/downwards/upwards degrades the results.\n",
        "5. The person's face should not be occluded (or partially occluded) by any item.\n",
        "6. Both eyes should be open and visible. (eyeglasses are ok, no sunglasses)\n",
        "\n",
        "Your uploaded images are local to the Colab instance and are not accessible by the paper authors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSUbmd697Api",
        "collapsed": true
      },
      "source": [
        "# upload your image (the code supports only a single image at a time)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  img_path = filename\n",
        "  print('User uploaded file \"{name}\"'.format(name=filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgxXQ4tu45V5"
      },
      "source": [
        "Finally, we preprocess the image, run the network, and save the result."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_drive_path = '/content/drive/My Drive/Lifespane'\n",
        "os.makedirs(base_drive_path, exist_ok=True)\n",
        "image_folder_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "image_folder_path = os.path.join(base_drive_path, image_folder_name)\n",
        "os.makedirs(image_folder_path, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "NWZR6ALIB9II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ3Az0VY3Fwt"
      },
      "source": [
        "data = dataset.dataset.get_item_from_path(img_path)\n",
        "visuals = model.inference(data)\n",
        "\n",
        "os.makedirs('results', exist_ok=True)\n",
        "out_path = os.path.join(image_folder_path, os.path.splitext(img_path)[0].replace(' ', '_') + '.png')\n",
        "visualizer.save_images_deploy(visuals, out_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRCyM2i65ZdB"
      },
      "source": [
        "Let's display at the results.\n",
        "\n",
        "NOTE: if you're using chrome, uncomment the lines below. For some reason, mp4 files won't display on chrome browser, so we need to convert to webm."
      ]
    }
  ]
}